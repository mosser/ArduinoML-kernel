"use strict";
/******************************************************************************
 * Copyright 2022 TypeFox GmbH
 * This program and the accompanying materials are made available under the
 * terms of the MIT License, which is available in the project root.
 ******************************************************************************/
Object.defineProperty(exports, "__esModule", { value: true });
exports.SemanticTokensDecoder = exports.AbstractSemanticTokenProvider = exports.SemanticTokensBuilder = exports.DefaultSemanticTokenOptions = exports.AllSemanticTokenModifiers = exports.AllSemanticTokenTypes = void 0;
/* eslint-disable no-bitwise */
const vscode_languageserver_1 = require("vscode-languageserver");
const grammar_util_1 = require("../utils/grammar-util");
const ast_util_1 = require("../utils/ast-util");
exports.AllSemanticTokenTypes = {
    [vscode_languageserver_1.SemanticTokenTypes.class]: 0,
    [vscode_languageserver_1.SemanticTokenTypes.comment]: 1,
    [vscode_languageserver_1.SemanticTokenTypes.enum]: 2,
    [vscode_languageserver_1.SemanticTokenTypes.enumMember]: 3,
    [vscode_languageserver_1.SemanticTokenTypes.event]: 4,
    [vscode_languageserver_1.SemanticTokenTypes.function]: 5,
    [vscode_languageserver_1.SemanticTokenTypes.interface]: 6,
    [vscode_languageserver_1.SemanticTokenTypes.keyword]: 7,
    [vscode_languageserver_1.SemanticTokenTypes.macro]: 8,
    [vscode_languageserver_1.SemanticTokenTypes.method]: 9,
    [vscode_languageserver_1.SemanticTokenTypes.modifier]: 10,
    [vscode_languageserver_1.SemanticTokenTypes.namespace]: 11,
    [vscode_languageserver_1.SemanticTokenTypes.number]: 12,
    [vscode_languageserver_1.SemanticTokenTypes.operator]: 13,
    [vscode_languageserver_1.SemanticTokenTypes.parameter]: 14,
    [vscode_languageserver_1.SemanticTokenTypes.property]: 15,
    [vscode_languageserver_1.SemanticTokenTypes.regexp]: 16,
    [vscode_languageserver_1.SemanticTokenTypes.string]: 17,
    [vscode_languageserver_1.SemanticTokenTypes.struct]: 18,
    [vscode_languageserver_1.SemanticTokenTypes.type]: 19,
    [vscode_languageserver_1.SemanticTokenTypes.typeParameter]: 20,
    [vscode_languageserver_1.SemanticTokenTypes.variable]: 21
};
exports.AllSemanticTokenModifiers = {
    [vscode_languageserver_1.SemanticTokenModifiers.abstract]: 1 << 0,
    [vscode_languageserver_1.SemanticTokenModifiers.async]: 1 << 1,
    [vscode_languageserver_1.SemanticTokenModifiers.declaration]: 1 << 2,
    [vscode_languageserver_1.SemanticTokenModifiers.defaultLibrary]: 1 << 3,
    [vscode_languageserver_1.SemanticTokenModifiers.definition]: 1 << 4,
    [vscode_languageserver_1.SemanticTokenModifiers.deprecated]: 1 << 5,
    [vscode_languageserver_1.SemanticTokenModifiers.documentation]: 1 << 6,
    [vscode_languageserver_1.SemanticTokenModifiers.modification]: 1 << 7,
    [vscode_languageserver_1.SemanticTokenModifiers.readonly]: 1 << 8,
    [vscode_languageserver_1.SemanticTokenModifiers.static]: 1 << 9
};
exports.DefaultSemanticTokenOptions = {
    legend: {
        tokenTypes: Object.keys(exports.AllSemanticTokenTypes),
        tokenModifiers: Object.keys(exports.AllSemanticTokenModifiers)
    },
    full: {
        delta: true
    },
    range: true
};
class SemanticTokensBuilder extends vscode_languageserver_1.SemanticTokensBuilder {
    constructor() {
        super(...arguments);
        this._tokens = [];
    }
    push(line, char, length, tokenType, tokenModifiers) {
        this._tokens.push({
            line,
            char,
            length,
            tokenType,
            tokenModifiers
        });
    }
    build() {
        this.applyTokens();
        return super.build();
    }
    buildEdits() {
        this.applyTokens();
        return super.buildEdits();
    }
    applyTokens() {
        for (const token of this._tokens.sort(this.compareTokens)) {
            super.push(token.line, token.char, token.length, token.tokenType, token.tokenModifiers);
        }
        this._tokens = [];
    }
    compareTokens(a, b) {
        if (a.line === b.line) {
            return a.char - b.char;
        }
        return a.line - b.line;
    }
}
exports.SemanticTokensBuilder = SemanticTokensBuilder;
/**
 * A basic super class for providing semantic token data.
 * Users of Langium should extend this class to create their own `SemanticTokenProvider`.
 *
 * The entry method for generating semantic tokens based on an `AstNode` is the `highlightElement` method.
 */
class AbstractSemanticTokenProvider {
    constructor(services) {
        /**
         * Store a token builder for each open document.
         */
        this.tokensBuilders = new Map();
        // Delete the token builder once the text document has been closed
        services.shared.workspace.TextDocuments.onDidClose(e => {
            this.tokensBuilders.delete(e.document.uri);
        });
        services.shared.lsp.LanguageServer.onInitialize(params => {
            var _a;
            this.initialize((_a = params.capabilities.textDocument) === null || _a === void 0 ? void 0 : _a.semanticTokens);
        });
    }
    initialize(clientCapabilities) {
        this.clientCapabilities = clientCapabilities;
    }
    semanticHighlight(document, _params, cancelToken = vscode_languageserver_1.CancellationToken.None) {
        this.currentRange = undefined;
        this.currentDocument = document;
        this.currentTokensBuilder = this.getDocumentTokensBuilder(document);
        this.computeHighlighting(document, this.createAcceptor(), cancelToken);
        return this.currentTokensBuilder.build();
    }
    semanticHighlightRange(document, params, cancelToken = vscode_languageserver_1.CancellationToken.None) {
        this.currentRange = params.range;
        this.currentDocument = document;
        this.currentTokensBuilder = this.getDocumentTokensBuilder(document);
        this.computeHighlighting(document, this.createAcceptor(), cancelToken);
        return this.currentTokensBuilder.build();
    }
    semanticHighlightDelta(document, params, cancelToken = vscode_languageserver_1.CancellationToken.None) {
        this.currentRange = undefined;
        this.currentDocument = document;
        this.currentTokensBuilder = this.getDocumentTokensBuilder(document);
        this.currentTokensBuilder.previousResult(params.previousResultId);
        this.computeHighlighting(document, this.createAcceptor(), cancelToken);
        return this.currentTokensBuilder.buildEdits();
    }
    createAcceptor() {
        const acceptor = options => {
            if ('line' in options) {
                this.highlightToken({
                    range: {
                        start: {
                            line: options.line,
                            character: options.char
                        },
                        end: {
                            line: options.line,
                            character: options.char + options.length
                        }
                    },
                    type: options.type,
                    modifier: options.modifier
                });
            }
            else if ('range' in options) {
                this.highlightToken(options);
            }
            else if ('keyword' in options) {
                this.highlightKeyword(options);
            }
            else if ('property' in options) {
                this.highlightProperty(options);
            }
            else {
                this.highlightNode({
                    node: options.cst,
                    type: options.type,
                    modifier: options.modifier
                });
            }
        };
        return acceptor;
    }
    getDocumentTokensBuilder(document) {
        const existing = this.tokensBuilders.get(document.uri.toString());
        if (existing) {
            return existing;
        }
        const builder = new SemanticTokensBuilder();
        this.tokensBuilders.set(document.uri.toString(), builder);
        return builder;
    }
    computeHighlighting(document, acceptor, cancelToken) {
        const root = document.parseResult.value;
        if (this.highlightElement(root, acceptor) === 'prune') {
            // If the root node is pruned, we can return here already
            return;
        }
        const treeIterator = (0, ast_util_1.streamAllContents)(root).iterator();
        let result;
        do {
            result = treeIterator.next();
            if (!result.done) {
                if (cancelToken.isCancellationRequested) {
                    break;
                }
                const node = result.value;
                const nodeRange = node.$cstNode.range;
                const comparedRange = this.compareRange(nodeRange);
                if (comparedRange === 1) {
                    break; // Every following element will not be in range, so end the loop
                }
                else if (comparedRange === -1) {
                    continue; // Current element is ending before range starts, skip to next element
                }
                if (this.highlightElement(node, acceptor) === 'prune') {
                    treeIterator.prune();
                }
            }
        } while (!result.done);
    }
    compareRange(range) {
        if (!this.currentRange) {
            return 0;
        }
        const startLine = typeof range === 'number' ? range : range.start.line;
        const endLine = typeof range === 'number' ? range : range.end.line;
        if (endLine < this.currentRange.start.line) {
            return -1;
        }
        else if (startLine > this.currentRange.end.line) {
            return 1;
        }
        else {
            return 0;
        }
    }
    highlightToken(options) {
        var _a;
        const { range, type } = options;
        let modifiers = options.modifier;
        if (this.compareRange(range) !== 0 || !this.currentDocument || !this.currentTokensBuilder) {
            return;
        }
        const intType = exports.AllSemanticTokenTypes[type];
        let totalModifier = 0;
        if (modifiers !== undefined) {
            if (typeof modifiers === 'string') {
                modifiers = [modifiers];
            }
            for (const modifier of modifiers) {
                const intModifier = exports.AllSemanticTokenModifiers[modifier];
                totalModifier |= intModifier;
            }
        }
        const startLine = range.start.line;
        const endLine = range.end.line;
        if (startLine === endLine) {
            // Token only spans a single line
            const char = range.start.character;
            const length = range.end.character - char;
            this.currentTokensBuilder.push(startLine, char, length, intType, totalModifier);
        }
        else if ((_a = this.clientCapabilities) === null || _a === void 0 ? void 0 : _a.multilineTokenSupport) {
            // Let token span multiple lines
            const startChar = range.start.character;
            const startOffset = this.currentDocument.textDocument.offsetAt(range.start);
            const endOffset = this.currentDocument.textDocument.offsetAt(range.end);
            this.currentTokensBuilder.push(startLine, startChar, endOffset - startOffset, intType, totalModifier);
        }
        else {
            // Token spans multiple lines, but the client doesn't support it
            // Split the range into multiple semantic tokens
            const firstLineStart = range.start;
            let nextLineOffset = this.currentDocument.textDocument.offsetAt({
                line: startLine + 1,
                character: 0
            });
            // Build first line
            this.currentTokensBuilder.push(firstLineStart.line, firstLineStart.character, nextLineOffset - firstLineStart.character - 1, intType, totalModifier);
            // Build all lines in between first and last
            for (let i = startLine + 1; i < endLine; i++) {
                const currentLineOffset = nextLineOffset;
                nextLineOffset = this.currentDocument.textDocument.offsetAt({
                    line: i + 1,
                    character: 0
                });
                this.currentTokensBuilder.push(i, 0, nextLineOffset - currentLineOffset - 1, intType, totalModifier);
            }
            // Build last line
            this.currentTokensBuilder.push(endLine, 0, range.end.character, intType, totalModifier);
        }
    }
    highlightProperty(options) {
        const nodes = [];
        if (typeof options.index === 'number') {
            const node = (0, grammar_util_1.findNodeForProperty)(options.node.$cstNode, options.property, options.index);
            if (node) {
                nodes.push(node);
            }
        }
        else {
            nodes.push(...(0, grammar_util_1.findNodesForProperty)(options.node.$cstNode, options.property));
        }
        const { type, modifier } = options;
        for (const node of nodes) {
            this.highlightNode({
                node,
                type,
                modifier
            });
        }
    }
    highlightKeyword(options) {
        const { node, keyword, type, index, modifier } = options;
        const nodes = [];
        if (typeof index === 'number') {
            const keywordNode = (0, grammar_util_1.findNodeForKeyword)(node.$cstNode, keyword, index);
            if (keywordNode) {
                nodes.push(keywordNode);
            }
        }
        else {
            nodes.push(...(0, grammar_util_1.findNodesForKeyword)(node.$cstNode, keyword));
        }
        for (const keywordNode of nodes) {
            this.highlightNode({
                node: keywordNode,
                type,
                modifier
            });
        }
    }
    highlightNode(options) {
        const { node, type, modifier } = options;
        const range = node.range;
        this.highlightToken({
            range,
            type,
            modifier
        });
    }
}
exports.AbstractSemanticTokenProvider = AbstractSemanticTokenProvider;
var SemanticTokensDecoder;
(function (SemanticTokensDecoder) {
    function decode(tokens, document) {
        const typeMap = new Map();
        Object.entries(exports.AllSemanticTokenTypes).forEach(([type, index]) => typeMap.set(index, type));
        let line = 0;
        let character = 0;
        return sliceIntoChunks(tokens.data, 5).map(t => {
            line += t[0];
            if (t[0] !== 0) {
                character = 0;
            }
            character += t[1];
            const length = t[2];
            const offset = document.textDocument.offsetAt({ line, character });
            return {
                offset,
                tokenType: typeMap.get(t[3]),
                tokenModifiers: t[4],
                text: document.textDocument.getText({ start: { line, character }, end: { line, character: character + length } })
            };
        });
    }
    SemanticTokensDecoder.decode = decode;
    function sliceIntoChunks(arr, chunkSize) {
        const res = [];
        for (let i = 0; i < arr.length; i += chunkSize) {
            const chunk = arr.slice(i, i + chunkSize);
            res.push(chunk);
        }
        return res;
    }
})(SemanticTokensDecoder = exports.SemanticTokensDecoder || (exports.SemanticTokensDecoder = {}));
//# sourceMappingURL=semantic-token-provider.js.map